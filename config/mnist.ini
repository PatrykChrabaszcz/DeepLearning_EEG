[experiment]
model_class_name = SimpleRNN
reader_class_name = MnistDataReader
verbose = 1

[model]
rnn_hidden_size = 128
rnn_num_layers = 2
dropout_f = 0.0
dropout_h = 0.0
dropout_i = 0.0
rnn_cell_type = GRU
rnn_normalization = none
use_context = 0
rnn_initial_state = zero
skip_mode = none


[data_reader]
data_path = /home/chrabasp/data/mnist
readers_count = 3
batch_size = 100
sequence_size = 784
validation_sequence_size = 784
validation_batch_size = 100
balanced = 1
random_mode = 0
continuous = 1
limit_examples = 0
limit_duration = 0
forget_state = 1
cv_n = 9
cv_k = 8

[model_trainer]
budget = 1000
budget_type = iteration
metrics_class = SingleLabelMetrics
lr = 0.001
l2_decay = 0.0
weight_decay = 0.0
objective_type = CrossEntropy_last
cosine_decay = 0
optimizer = ExtendedAdam


[bayesian_optimizer]
working_dir = /home/chrabasp/mnist_10_3
n_iterations = 100
eta = 3
min_budget = 1
max_budget = 27


[config_generator]
min_points_in_model = 10
top_n_percent = 15
num_samples = 27
random_fraction = 0.2
bandwidth_factor = 3
